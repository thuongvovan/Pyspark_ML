{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 11 - EXERCISE 1: HAM VS SPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= SparkContext(master= 'local', appName= 'Chapter 11 - Exercise 1: Ham vs Spam')\n",
    "ss= SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nhập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/Users/vovanthuong/Desktop/9 - Big Data in Machine Learning/Data/LDS9_Data_Day_9_Day_10/smsspamcollection/SMSSpamCollection'\n",
    "data= ss.read.csv(path, inferSchema= True, sep= '\\t').toDF('label', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mô tả dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  ham| 4827|\n",
      "| spam|  747|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|label|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "data.withColumn('length', length('text')).groupBy('label').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo tập train và test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test= data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "# 1\n",
    "regex_tokenizer= RegexTokenizer(inputCol= 'text', outputCol= 'words',\n",
    "                                pattern= '\\\\W', toLowercase= True)\n",
    "# 2\n",
    "locale = sc._jvm.java.util.Locale\n",
    "locale.setDefault(locale.forLanguageTag(\"en-US\"))\n",
    "stop_words_remover= StopWordsRemover(inputCol= 'words', outputCol= 'words_filtered')\n",
    "\n",
    "# 3: TF\n",
    "count_vectorizer= CountVectorizer(inputCol= 'words_filtered', outputCol= 'tf')\n",
    "\n",
    "# 4\n",
    "tf_idf= IDF(inputCol= 'tf', outputCol= 'tf_idf')\n",
    "\n",
    "# 5\n",
    "str_indexer= StringIndexer(inputCol= 'label', outputCol= 'label_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "process= Pipeline(stages=[regex_tokenizer, # 1\n",
    "                          stop_words_remover, # 2\n",
    "                          count_vectorizer, # 3\n",
    "                            tf_idf, # 4\n",
    "                            str_indexer]) # 5\n",
    "process_model= process.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned= process_model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "naive_bayes= NaiveBayes(featuresCol= 'tf_idf', labelCol= 'label_idx')\n",
    "\n",
    "naive_bayes_model= naive_bayes.fit(train_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "area_under_ROC= BinaryClassificationEvaluator(labelCol= 'label_idx', \n",
    "                                                  metricName= 'areaUnderROC')\n",
    "\n",
    "area_under_PR= BinaryClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  metricName= 'areaUnderPR')\n",
    "\n",
    "accuracy= MulticlassClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  predictionCol= 'prediction',\n",
    "                                                  metricName= 'accuracy')\n",
    "f1= MulticlassClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  predictionCol= 'prediction',\n",
    "                                                  metricName= 'f1')\n",
    "\n",
    "precision= MulticlassClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  predictionCol= 'prediction',\n",
    "                                                  metricName= 'weightedPrecision')\n",
    "\n",
    "recall= MulticlassClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  predictionCol= 'prediction',\n",
    "                                                  metricName= 'weightedRecall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(data_result):\n",
    "    data_result.crosstab(col1= 'prediction', col2= 'label_idx').show()\n",
    "    print('areaUnderROC:' ,area_under_ROC.evaluate(data_result))\n",
    "    print('areaUnderPR:' ,area_under_PR.evaluate(data_result))\n",
    "    print('accuracy:' ,accuracy.evaluate(data_result))\n",
    "    print('f1:' ,f1.evaluate(data_result))\n",
    "    print('precision:' ,precision.evaluate(data_result))\n",
    "    print('recall:' ,recall.evaluate(data_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result= naive_bayes_model.transform(train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+\n",
      "|prediction_label_idx| 0.0|1.0|\n",
      "+--------------------+----+---+\n",
      "|                 1.0|  29|607|\n",
      "|                 0.0|3855|  3|\n",
      "+--------------------+----+---+\n",
      "\n",
      "areaUnderROC: 0.19158337694788202\n",
      "areaUnderPR: 0.08126654772202971\n",
      "accuracy: 0.9928793947485536\n",
      "f1: 0.9929417301943152\n",
      "precision: 0.993138699791233\n",
      "recall: 0.9928793947485536\n"
     ]
    }
   ],
   "source": [
    "evaluator(train_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cleaned= process_model.transform(test)\n",
    "test_result= naive_bayes_model.transform(test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---+\n",
      "|prediction_label_idx|0.0|1.0|\n",
      "+--------------------+---+---+\n",
      "|                 1.0| 17|132|\n",
      "|                 0.0|926|  5|\n",
      "+--------------------+---+---+\n",
      "\n",
      "areaUnderROC: 0.20756863868226128\n",
      "areaUnderPR: 0.07641802632099842\n",
      "accuracy: 0.9796296296296296\n",
      "f1: 0.9799917600878113\n",
      "precision: 0.9808376673013096\n",
      "recall: 0.9796296296296296\n"
     ]
    }
   ],
   "source": [
    "evaluator(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
