{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 11 - EXERCISE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= SparkContext(master= 'local', appName= 'Chapter 11 - Exercise 2')\n",
    "ss= SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nhập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/Users/vovanthuong/Desktop/9 - Big Data in Machine Learning/Data/LDS9_Data_Day_9_Day_10/Musical_Instruments_5.json'\n",
    "data= ss.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "|1384719342|  [0, 0]|    5.0|Not much to write...|02 28, 2014|A2IBPI20UZIR0U|cassandra tu \"Yea...|                good|    1393545600|\n",
      "|1384719342|[13, 14]|    5.0|The product does ...|03 16, 2013|A14VAT5EAX3D9S|                Jake|                Jake|    1363392000|\n",
      "|1384719342|  [1, 1]|    5.0|The primary job o...|08 28, 2013|A195EZSQDW3E21|Rick Bennette \"Ri...|It Does The Job Well|    1377648000|\n",
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mô tả dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|overall|count|\n",
      "+-------+-----+\n",
      "|    1.0|  217|\n",
      "|    4.0| 2084|\n",
      "|    3.0|  772|\n",
      "|    2.0|  250|\n",
      "|    5.0| 6938|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('overall').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----------------+\n",
      "|overall|avg(overall)|      avg(length)|\n",
      "+-------+------------+-----------------+\n",
      "|    1.0|         1.0|539.0829493087558|\n",
      "|    4.0|         4.0|540.3258157389636|\n",
      "|    3.0|         3.0|579.2111398963731|\n",
      "|    2.0|         2.0|          614.032|\n",
      "|    5.0|         5.0|452.9315364658403|\n",
      "+-------+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "data.withColumn('length', length('reviewText'))\\\n",
    ".select('overall', 'length')\\\n",
    ".groupBy('overall').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo tập train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test= data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import SQLTransformer, RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.feature import IDF, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "select_columns= SQLTransformer(statement= 'SELECT overall, reviewText FROM __THIS__')\n",
    "# 2\n",
    "sql_query_label= '''\n",
    "SELECT *, \n",
    "        CASE WHEN (overall <= 2) THEN 'Not_like' \n",
    "             WHEN (overall >= 4)  THEN 'Like' \n",
    "             ELSE 'Neutral' \n",
    "        END as label\n",
    "FROM __THIS__'''\n",
    "create_label_output= SQLTransformer(statement= sql_query_label)\n",
    "# 3\n",
    "regex_tokenizer= RegexTokenizer(inputCol= 'reviewText', outputCol= 'words',\n",
    "                                pattern= '\\\\W', toLowercase= True)\n",
    "# 4\n",
    "locale = sc._jvm.java.util.Locale\n",
    "locale.setDefault(locale.forLanguageTag(\"en-US\"))\n",
    "stop_words_remover= StopWordsRemover(inputCol= 'words', outputCol= 'words_filtered')\n",
    "# 5 TF\n",
    "count_vectorizer= CountVectorizer(inputCol= 'words_filtered', outputCol= 'tf')\n",
    "# 6 TF-IDF\n",
    "tf_idf= IDF(inputCol= 'tf', outputCol= 'tf_idf')\n",
    "# 7\n",
    "str_indexer= StringIndexer(inputCol= 'label', outputCol= 'label_idx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "process= Pipeline(stages= [select_columns, # 1\n",
    "                           create_label_output, # 2\n",
    "                           regex_tokenizer, # 3\n",
    "                           stop_words_remover, # 4\n",
    "                           count_vectorizer, #5\n",
    "                           tf_idf, # 6\n",
    "                           str_indexer]) # 7\n",
    "process_model= process.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xây dựng mô hình phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned= process_model.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "naive_bayes= NaiveBayes(featuresCol= 'tf_idf', labelCol= 'label_idx', predictionCol= 'prediction_idx')\n",
    "\n",
    "# relabel\n",
    "label_lis= process_model.stages[6].labels\n",
    "condition_lis= []\n",
    "for index, label in zip(range(len(label_lis)), label_lis):\n",
    "    condition_lis.append(\"WHEN (prediction_idx == {index}) THEN '{label}'\".format(index= index, label= label)) \n",
    "\n",
    "sql_query_relabel= '''\n",
    "SELECT *, CASE {condition}  END as prediction_label\n",
    "FROM __THIS__\n",
    "'''.format(condition= ' '.join(condition_lis))\n",
    "\n",
    "create_label_prediction= SQLTransformer(statement= sql_query_relabel)\n",
    "\n",
    "naive_bayes_pipe= Pipeline(stages= [process, # 1\n",
    "                                    naive_bayes, # 2\n",
    "                                    create_label_prediction]) # 3\n",
    "\n",
    "naive_bayes_model= naive_bayes_pipe.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy= MulticlassClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  predictionCol= 'prediction_idx',\n",
    "                                                  metricName= 'accuracy')\n",
    "f1= MulticlassClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  predictionCol= 'prediction_idx',\n",
    "                                                  metricName= 'f1')\n",
    "\n",
    "precision= MulticlassClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  predictionCol= 'prediction_idx',\n",
    "                                                  metricName= 'weightedPrecision')\n",
    "\n",
    "recall= MulticlassClassificationEvaluator(labelCol= 'label_idx',\n",
    "                                                  predictionCol= 'prediction_idx',\n",
    "                                                  metricName= 'weightedRecall')\n",
    "def evaluator(data_result):\n",
    "    data_result.crosstab(col1= 'prediction_label', col2= 'label').show()\n",
    "    print('accuracy:' ,accuracy.evaluate(data_result))\n",
    "    print('f1:' ,f1.evaluate(data_result))\n",
    "    print('precision:' ,precision.evaluate(data_result))\n",
    "    print('recall:' ,recall.evaluate(data_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----+-------+--------+\n",
      "|prediction_label_label|Like|Neutral|Not_like|\n",
      "+----------------------+----+-------+--------+\n",
      "|              Not_like| 110|      5|     364|\n",
      "|                  Like|6809|     75|      20|\n",
      "|               Neutral| 258|    552|       7|\n",
      "+----------------------+----+-------+--------+\n",
      "\n",
      "accuracy: 0.9420731707317073\n",
      "f1: 0.9450874556874358\n",
      "precision: 0.9515093842235908\n",
      "recall: 0.9420731707317074\n"
     ]
    }
   ],
   "source": [
    "train_naive_bayes_result= naive_bayes_model.transform(train)\n",
    "evaluator(train_naive_bayes_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----+-------+--------+\n",
      "|prediction_label_label|Like|Neutral|Not_like|\n",
      "+----------------------+----+-------+--------+\n",
      "|              Not_like|  44|     19|      18|\n",
      "|                  Like|1679|     99|      42|\n",
      "|               Neutral| 122|     22|      16|\n",
      "+----------------------+----+-------+--------+\n",
      "\n",
      "accuracy: 0.834061135371179\n",
      "f1: 0.8386283445303847\n",
      "precision: 0.8433780085890712\n",
      "recall: 0.8340611353711791\n"
     ]
    }
   ],
   "source": [
    "test_naive_bayes_result= naive_bayes_model.transform(test)\n",
    "evaluator(test_naive_bayes_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
