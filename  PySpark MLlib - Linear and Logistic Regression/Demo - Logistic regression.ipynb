{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xây dựng logistic model để dự đoán chuyến bay có bị trễ hay không từ các biến:  \n",
    "- mon  \n",
    "- dom  \n",
    "- dow  \n",
    "- carrier  \n",
    "- org  \n",
    "- km (mile * 1.60934)  \n",
    "- depart  \n",
    "- duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nhập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= SparkContext(master= 'local', appName= 'Demo Logistic regression')\n",
    "ss= SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '/Users/vovanthuong/Desktop/9 - Big Data in Machine Learning/Data/Data ML/flights.csv'\n",
    "df= ss.read.csv(path= path, inferSchema= True, header= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mon: integer (nullable = true)\n",
      " |-- dom: integer (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- mile: integer (nullable = true)\n",
      " |-- depart: double (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- delay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65|   NA|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo biến km\n",
    "from pyspark.sql.functions import round\n",
    "df= df.withColumn('km', round(col('mile') * 1.60934, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|3465.0| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8| 542.0|    0|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|1989.0|    0|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65|   NA| 415.0| null|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mã hóa biến delay. Nếu delay >= 15 = 1\n",
    "df= df.withColumn('label', (col('delay') >= 15).cast('integer'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8| 542.0|    0|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|1989.0|    0|\n",
      "|  5|  2|  1|     UA|   704|SFO| 550|  7.98|     102|    2| 885.0|    0|\n",
      "|  7|  2|  6|     AA|   380|ORD| 733| 10.83|     135|   54|1180.0|    1|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Xóa các dòng mà label NA\n",
    "df= df.dropna(how= 'any', subset= 'label')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo dữ liệu train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test= df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuyển đổi dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mã hóa các biến số định danh (carrier và org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator\n",
    "# Mã hóa biến số carrier thành dạng số\n",
    "carrier_indexer= StringIndexer(inputCol= 'carrier', outputCol= 'carrier_idx')\n",
    "carrier_indexer= carrier_indexer.fit(train)\n",
    "train= carrier_indexer.transform(train)\n",
    "# Mã hóa biến số org thành dạng số\n",
    "org_indexer= StringIndexer(inputCol=  'org', outputCol=  'org_idx')\n",
    "org_indexer= org_indexer.fit(train)\n",
    "train= org_indexer.transform(train)\n",
    "# Onehot encoding\n",
    "oh_encoder= OneHotEncoderEstimator(inputCols= ['carrier_idx', 'org_idx'], outputCols= ['carrier_dummy', 'org_dummy'])\n",
    "oh_encoder= oh_encoder.fit(train)\n",
    "train= oh_encoder.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|    km|label|carrier_idx|org_idx|carrier_dummy|    org_dummy|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+\n",
      "|  0|  1|  2|     AA|    73|ORD|4243|  9.08|     560|   39|6828.0|    1|        1.0|    0.0|(8,[1],[1.0])|(7,[0],[1.0])|\n",
      "|  0|  1|  2|     AA|   150|SFO|2704| 23.42|     325|   22|4352.0|    1|        1.0|    1.0|(8,[1],[1.0])|(7,[1],[1.0])|\n",
      "|  0|  1|  2|     AA|   154|ORD| 867| 17.25|     135|   49|1395.0|    1|        1.0|    0.0|(8,[1],[1.0])|(7,[0],[1.0])|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+------+-----+-----------+-------+-------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tạo vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler= VectorAssembler(inputCols= ['mon', 'dom', 'dow', 'flight', 'depart', 'duration', 'km', 'carrier_dummy', 'org_dummy'],\n",
    "                           outputCol= 'features')\n",
    "train= assembler.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+-----+\n",
      "|features                                                          |label|\n",
      "+------------------------------------------------------------------+-----+\n",
      "|(22,[1,2,3,4,5,6,8,15],[1.0,2.0,73.0,9.08,560.0,6828.0,1.0,1.0])  |1    |\n",
      "|(22,[1,2,3,4,5,6,8,16],[1.0,2.0,150.0,23.42,325.0,4352.0,1.0,1.0])|1    |\n",
      "|(22,[1,2,3,4,5,6,8,15],[1.0,2.0,154.0,17.25,135.0,1395.0,1.0,1.0])|1    |\n",
      "|(22,[1,2,3,4,5,6,8,17],[1.0,2.0,181.0,17.0,379.0,3983.0,1.0,1.0]) |0    |\n",
      "|(22,[1,2,3,4,5,6,8],[1.0,2.0,254.0,15.33,310.0,4001.0,1.0])       |1    |\n",
      "|(22,[1,2,3,4,5,6,8,18],[1.0,2.0,317.0,9.92,170.0,1180.0,1.0,1.0]) |0    |\n",
      "|(22,[1,2,3,4,5,6,8,18],[1.0,2.0,335.0,14.58,165.0,1180.0,1.0,1.0])|0    |\n",
      "|(22,[1,2,3,4,5,6,8,15],[1.0,2.0,336.0,21.58,115.0,1180.0,1.0,1.0])|1    |\n",
      "|(22,[1,2,3,4,5,6,8,15],[1.0,2.0,346.0,19.5,130.0,1180.0,1.0,1.0]) |1    |\n",
      "|(22,[1,2,3,4,5,6,8,15],[1.0,2.0,354.0,17.58,130.0,1180.0,1.0,1.0])|1    |\n",
      "+------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('features', 'label').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale dữ liệu (lựa chọn minmax scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "mm_scaler= MinMaxScaler(inputCol= 'features', outputCol= 'features_scale')\n",
    "mm_scaler= mm_scaler.fit(train)\n",
    "train= mm_scaler.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xây dựng mô hình hồi quy Logistic trên tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lgr= LogisticRegression(featuresCol= 'features_scale', labelCol= 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr= lgr.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đánh giá mô hình hồi quy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đánh giá mô hình trên tập train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá mô hình bằng phương thức evaluate thuộc class LogisticRegression  \n",
    "Bằng phương thức này không cần thiết phải transform dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_evaluater= lgr.evaluate(dataset= train.select('features_scale', 'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6110313281208446"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_evaluater.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5535908596300326, 0.6659556757881594]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_evaluater.recallByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6130995420583273, 0.609397315052842]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_evaluater.precisionByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6534309616893683"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr_evaluater.areaUnderROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá mô hình bằng class BinaryClassificationEvaluator và MulticlassClassificationEvaluator trong modul evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_evalaluator= MulticlassClassificationEvaluator(labelCol= 'label',\n",
    "                                                              predictionCol= 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6097362212301496"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_evalaluator.setMetricName('f1').evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6112069776335776"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_evalaluator.setMetricName('weightedPrecision').evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6110313281208446"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_evalaluator.setMetricName('weightedRecall').evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6110313281208446"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_evalaluator.setMetricName('accuracy').evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_classification_evalaluator= BinaryClassificationEvaluator(labelCol= 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6534364471069379"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_classification_evalaluator.setMetricName('areaUnderROC').evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6386669075509808"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_classification_evalaluator.setMetricName('areaUnderPR').evaluate(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nhận xét: Đánh giá bằng phương thức evaluate cho các chỉ số thông dụng còn đánh giá mô hình phân loại bằng modul evaluation cho các chỉ số chuyên sâu, ít thông dụng hơn. Vậy nên phân tích hồi quy logistic theo hướng: sử dụng pipeline để chuyển đổi dữ liệu mà không đưa đối tượng hồi quy vào pipeline.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu và load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Lưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr.save('Logistic regression model demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import  LogisticRegressionModel\n",
    "lgr_load= LogisticRegressionModel.load('Logistic regression model demo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
